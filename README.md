This repository explores how to push a deep learning model to the limits with little data. In particular, I look at model architecture, data augmentation and pseudo-labeling.

You can read more about the approach I take [here](https://medium.com/@radekosmulski/beating-the-state-of-the-art-from-2013-with-5-of-data-without-using-transfer-learning-301faf624fb6).

To run the code:

1. `cd` into the cloned repository
2. Download the [dogs vs cats](https://www.kaggle.com/c/dogs-vs-cats) dataset manually or if you have the kaggle-cli configured, run `kg download`
3. Execute `unzip train.zip` from the root of the repository
4. Run the notebook
